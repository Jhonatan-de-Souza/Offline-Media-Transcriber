# Audio Transcriber

Convert any audio or video file to text‚Äîcompletely offline and private. Choose between CPU-optimized (recommended) or GPU-accelerated depending on your hardware.

![CPU-Based Transcriber](./CPU%20Based%20Audio%20Transcriber//assets/cpu_audio_transcriber.png)

## Why Audio Transcriber?

‚úÖ **Works offline** ‚Äî No cloud uploads, no account needed  
‚úÖ **Fast and accurate** ‚Äî Powered by advanced AI models  
‚úÖ **Free and open** ‚Äî No subscriptions or usage limits  
‚úÖ **Cross-platform** ‚Äî Windows, macOS, and Linux supported  
‚úÖ **Choose your tool** ‚Äî CPU for optimal speed and good accurary, GPU for much slower, but more accuracy  

---

## ‚ö° Quick Comparison

| Feature | CPU-Based | GPU-Based |
|---------|-----------|-----------|
| **Best for** | Most users, laptops | Batch processing |
| **Engine** | Parakeet V3 (ONNX) | Whisper AI (PyTorch) |
| **Speed** | Fast | Slower (2-5x on average) |
| **Setup** | Simple | Requires CUDA setup |
| **GPU needed** | No | Yes (NVIDIA) |
| **Model size** | ~671MB | ~1GB |

**‚Üí Recommended: Start with CPU-based for fastest transcription.**

---

## üöÄ CPU-Based Transcriber (Recommended)

This is the easiest option. It works on any computer without requiring a GPU.

### Installation

**Step 1: Navigate to the CPU folder**

```bash
cd "CPU Based Audio Transcriber"
```

**Step 2: Create a virtual environment**

macOS / Linux:

```bash
python3 -m venv venv
source venv/bin/activate
```

Windows (PowerShell):

```powershell
python -m venv venv
venv\Scripts\Activate.ps1
```

Windows (Command Prompt):

```cmd
python -m venv venv
venv\Scripts\activate.bat
```

**Step 3: Install dependencies**

```bash
pip install -r requirements.txt
```

**Step 4 (Optional): Install FFmpeg for video support**

macOS:

```bash
brew install ffmpeg
```

Ubuntu / Debian:

```bash
sudo apt-get install ffmpeg
```

Windows:

```bash
choco install ffmpeg
```

### Quick Start

Launch the app:

```bash
python app.py
```

**On first run:**
1. **Download splash screen** ‚Äî App automatically downloads AI models from Hugging Face (~671MB)
2. **Progress indicator** ‚Äî Shows download status
3. **Main window** ‚Äî Ready to transcribe

**Subsequent runs:**
1. **No splash screen** ‚Äî Models are cached locally, app starts instantly
2. **Loading screen** ‚Äî App loads the model into memory
3. **Main window** ‚Äî Ready to transcribe

Then:
1. Click **Browse** and select an audio or video file
2. Click **Transcribe**
3. Watch the countdown timer
4. Results appear automatically

### Supported File Types

**Audio:** MP3, WAV, M4A, FLAC, OGG, AIFF, AU, and more  
**Video:** MP4, MKV, AVI, MOV, WEBM, FLV, WMV, etc. (auto-converted)

### How It Works

- **Smart time estimation** ‚Äî App measures your CPU performance on startup
- **Accurate countdown** ‚Äî Timer shows real remaining time, not guesses
- **Responsive UI** ‚Äî Never freezes; cancel anytime
- **No language selection** ‚Äî Model auto-detects what you're speaking

### What Happens Behind the Scenes

```
1. Select file
  ‚Üì
2. App measures CPU speed (5-second benchmark)
  ‚Üì
3. Calculate: estimated_time = file_duration √ó your_cpu_speed
  ‚Üì
4. Transcribe with accurate countdown
  ‚Üì
5. Show results
```

### Project Files

```
CPU Based Audio Transcriber/
‚îú‚îÄ‚îÄ app.py                      # Main interface (start here)
‚îú‚îÄ‚îÄ config.py                   # Model auto-download configuration
‚îú‚îÄ‚îÄ download_splash.py          # Download progress splash screen
‚îú‚îÄ‚îÄ model_manager.py            # Parakeet V3 model loader
‚îú‚îÄ‚îÄ transcription_service.py    # Transcription engine
‚îú‚îÄ‚îÄ performance_profiler.py     # CPU benchmarking
‚îú‚îÄ‚îÄ video_converter.py          # Video-to-audio conversion
‚îú‚îÄ‚îÄ audio_handler.py            # Audio file loading
‚îú‚îÄ‚îÄ requirements.txt            # Dependencies list
‚îÇ
‚îú‚îÄ‚îÄ models/                     # ONNX model files (auto-downloaded on first run)
‚îÇ   ‚îú‚îÄ‚îÄ encoder.int8.onnx
‚îÇ   ‚îú‚îÄ‚îÄ decoder.int8.onnx
‚îÇ   ‚îú‚îÄ‚îÄ joiner.int8.onnx
‚îÇ   ‚îî‚îÄ‚îÄ tokens.txt
```

**Note:** Model files are automatically downloaded from Hugging Face on first run (~671MB). Subsequent runs use the cached models.
‚îÇ
‚îî‚îÄ‚îÄ assets/                     # UI resources
```

### System Requirements

- **Python:** 3.14+
- **RAM:** 2GB minimum (4GB recommended)
- **Disk:** 300MB for models
- **OS:** Windows, macOS (Intel/Apple Silicon), Linux

### Dependencies

- `sherpa-onnx>=1.9.0` ‚Äî ONNX runtime for Parakeet V3
- `soundfile>=0.12.1` ‚Äî Audio file reading
- `customtkinter>=5.0.0` ‚Äî Modern graphical interface
- `numpy>=1.21.0` ‚Äî Audio processing

---

## üéÆ GPU-Based Transcriber

Use this if you have an NVIDIA GPU for batch processing.

![GPU-Based Transcriber - Before](./GPU%20Based%20Audio%20Transcriber/modules/assets/before1.jpeg)
![GPU-Based Transcriber - After](./GPU%20Based%20Audio%20Transcriber/modules/assets/after2.jpeg)

### Installation

**Step 1: Navigate to the GPU folder**

```bash
cd "GPU Based Audio Transcriber"
```

**Step 2: Create a virtual environment**

macOS / Linux:

```bash
python3 -m venv venv
source venv/bin/activate
```

Windows (PowerShell):

```powershell
python -m venv venv
venv\Scripts\Activate.ps1
```

**Step 3: Install dependencies**

```bash
pip install -r requirements.txt
```

**Step 4: Install PyTorch with CUDA support**

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126
```

**Step 5: Verify GPU detection**

```bash
python -c "import torch; print('GPU available:', torch.cuda.is_available())"
```

If `True` appears, your GPU is ready. If `False`, see [GPU troubleshooting](#gpu-not-detected).

### Quick Start

```bash
python main.py
```

**On first run:**
1. **Download splash screen** ‚Äî App automatically downloads Whisper AI model from Hugging Face (~1GB)
2. **Progress indicator** ‚Äî Shows download status
3. **Splash screen** ‚Äî Model loads into memory
4. **Main window** ‚Äî Two columns for single/batch transcription

**Subsequent runs:**
1. **No download** ‚Äî Models are cached, app loads model directly
2. **Splash screen** ‚Äî Model loads into memory
3. **Main window** ‚Äî Ready to transcribe

Choose **Single File Transcription** or **Batch Processing**:

**Single File:**
1. Click **Browse File**
2. Select language
3. Click **Transcribe**

**Batch Processing:**
1. Click **Select Folder**
2. Choose output folder
3. Click **Start Batch**

### Features

- üåê **Multi-language** ‚Äî Supports multiple languages
- üìÅ **Batch processing** ‚Äî Transcribe entire folders automatically
- üíæ **Auto-save** ‚Äî Results saved to text files
- ‚è±Ô∏è **Real-time feedback** ‚Äî Monitor transcription progress

### Dependencies

- `torch>=2.0.0` ‚Äî PyTorch with CUDA support
- `openai-whisper>=20230314` ‚Äî Whisper speech recognition
- `pydub>=0.25.0` ‚Äî Audio handling
- `PyQt5>=5.0.0` ‚Äî Professional interface

**Note:** AI models are automatically downloaded from Hugging Face on first run (~1GB). Subsequent runs use the cached models.

---

## üìñ Detailed Usage Guide

### CPU Version: Full Workflow

**Example: Transcribe a podcast episode**

```
1. Start app: python app.py

2. App benchmarks your CPU (watch progress):
  "‚è≥ Starting CPU benchmark..."
  "‚úì CPU benchmark complete (RTF: 1.2x)"

3. Click "Browse" ‚Üí Select "podcast.mp4"

4. Click "Transcribe"
  Status: "‚è±Ô∏è 15.2s remaining"
  (countdown updates every 0.5 seconds)

5. Wait for transcription
  Status: "‚úì Ready"

6. Results appear in text box
  (Select all + copy, or save to file)
```

### GPU Version: Batch Processing

**Example: Transcribe 10 MP4 files**

```
1. Start app: python main.py
  (Splash screen shows model loading progress)

2. Click "Select Folder with Files"
  ‚Üí Choose folder with 10 MP4s

3. Shows "‚úì 10 file(s) found"

4. Click "Start Batch"
  ‚Üí Choose output folder

5. Watch real-time progress:
  "Processing 3/10: meeting-notes.mp4"
  "‚è±Ô∏è Est. Time: 2:45"

6. Results saved:
  ‚úì meeting-notes.txt
  ‚úì Q1-summary.txt
  ...
```

---

## üîß Troubleshooting

### CPU Version

#### "Module not found: sherpa_onnx"

**Cause:** Dependencies not installed in virtual environment  
**Solution:**

```bash
# Make sure virtual environment is activated
source venv/bin/activate  # macOS/Linux
# or
venv\Scripts\activate     # Windows

# Reinstall dependencies
pip install -r requirements.txt
```

#### "FFmpeg not found" (video files not working)

**Cause:** FFmpeg not installed on your system  
**Solution:**

macOS:

```bash
# Install Homebrew first if needed: https://brew.sh
brew install ffmpeg
```

Ubuntu / Debian:

```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

Windows:

```bash
# Option 1: Using Chocolatey (requires admin)
choco install ffmpeg

# Option 2: Manual download
# 1. Visit https://ffmpeg.org/download.html
# 2. Download Windows build
# 3. Extract to C:\ffmpeg
# 4. Add C:\ffmpeg\bin to PATH
```

#### "Model files not found"

**Cause:** Models are missing or in wrong location  
**Solution:**

```bash
# Check if models exist
ls models/

# Should show:
# encoder.int8.onnx
# decoder.int8.onnx
# joiner.int8.onnx
# tokens.txt

# If missing, you may need to re-clone the repository
```

#### Countdown timer seems wrong

**Cause:** CPU performance measurement may vary between runs  
**Solution:** Subsequent runs will provide better accuracy as the app learns your system performance.

### GPU Version

#### GPU not detected

**Cause:** Either no NVIDIA GPU, or CUDA not installed  
**Solution:**

```bash
# Check if you have an NVIDIA GPU
nvidia-smi

# If command not found, you need NVIDIA drivers
# Download from: https://www.nvidia.com/Download/driverDetails.aspx

# After installing drivers, reinstall PyTorch
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126
```

#### "CUDA out of memory"

**Cause:** Your GPU doesn't have enough VRAM  
**Solution:** Switch to CPU-based version or reduce batch size

```bash
# Use CPU instead
cd ../CPU\ Based\ Audio\ Transcriber
python app.py
```

#### Model loading hangs

**Cause:** First download taking too long (Whisper model needs to download)  
**Solution:** Be patient. Check internet connection. It's a one-time download.

```bash
# Check if it's downloading (on Windows, check Task Manager)
# Check if it's downloading (on Mac, check Activity Monitor)
# Check if it's downloading (on Linux, run: watch -n 1 'du -sh ~/.cache/huggingface/hub/')
```

---

## ‚öôÔ∏è Advanced Configuration

### CPU Version: Change Model Path

Edit `config.py`:

```python
MODEL_CONFIG = {
   "encoder_path": "./models/encoder.int8.onnx",  # ‚Üê Path to encoder
   "decoder_path": "./models/decoder.int8.onnx",
   "joiner_path": "./models/joiner.int8.onnx",
   "tokens_path": "./models/tokens.txt",
}
```

### Performance Tuning

**CPU Version:**
- Close other applications for best results
- System load will affect transcription speed

**GPU Version:**
- Better suited for batch processing multiple files
- Requires CUDA drivers and PyTorch setup

---

## üéØ Which Version Should I Choose?

**Choose CPU-Based if:**
- ‚úÖ You want the simplest setup
- ‚úÖ You don't have an NVIDIA GPU
- ‚úÖ You prefer the fastest transcription
- ‚úÖ You transcribe 1-2 files occasionally

**Choose GPU-Based if:**
- ‚úÖ You have an NVIDIA GPU
- ‚úÖ You transcribe batches of files regularly
- ‚úÖ You already have CUDA and PyTorch installed

---

## Privacy & Security

‚úÖ **100% Offline** ‚Äî All processing happens on your computer  
‚úÖ **No Cloud** ‚Äî Audio never leaves your device  
‚úÖ **No Account** ‚Äî No login, email, or registration required  
‚úÖ **No Tracking** ‚Äî No analytics, no telemetry, no ads  
‚úÖ **Open Source** ‚Äî Inspect the code anytime  

---

## üìù License

MIT ‚Äî Free to use, modify, and distribute

---

## ‚ùì FAQ

**Q: Can I use this without internet?**  
A: Yes! After you run the app once (models download), you can work completely offline.

**Q: Is there a file size limit?**  
A: No. Very large files will just take longer to transcribe.

**Q: Does it work on Mac with Apple Silicon?**  
A: Yes, the CPU version works on Apple Silicon (M1/M2/M3).

**Q: Can I batch transcribe with CPU version?**  
A: Not in the UI, but you can run multiple instances.

**Q: Can I improve transcription accuracy?**  
A: Use clear audio and minimize background noise for best results.

---

## ü§ù Contributing

Found a bug? Want to improve something?

1. Check existing [GitHub issues](https://github.com/Jhonatan-de-Souza/AudioTranscriber/issues)
2. Create a new issue with clear description
3. Submit a pull request with improvements

---
